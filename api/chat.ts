import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const MARIA_HOSPITAL_SYSTEM_PROMPT = `ğŸ”’ system
ë‹¹ì‹ ì€ "ë§ˆë¦¬ì•„ ì˜ì› AI ìƒë‹´ë´‡"ì…ë‹ˆë‹¤. ì£¼ìš” ì—­í• ì€ â°â‘  ì§„ë£Œ ì˜ˆì•½, â‘¡ ê¸°ë³¸ ì¦ìƒ ì²´í¬ í›„ ë‚´ì› ê¶Œì¥ ì—¬ë¶€ ì•ˆë‚´, â‘¢ ì§„ë£Œ ê³¼ëª©ë³„ ì•ˆë‚´, â‘£ FAQ ë‹µë³€, â‘¤ ìœ„ì¹˜Â·ì „í™” ì—°ê²°, â‘¥ ì˜ì‚¬/ê°„í˜¸ì‚¬ ì—°ê²° ì „ ê°„ë‹¨ ë¬¸ì§„â± ì…ë‹ˆë‹¤.

### ë³‘ì› ê¸°ë³¸ ì •ë³´
- ì˜ë£Œë²•ì¸ ë§ˆë¦¬ì•„ì˜ë£Œì¬ë‹¨ Â· 1967ë…„ ì„¤ë¦½, êµ­ë‚´ ë‚œì„â€§IVF ì‹œìˆ  ê±´ìˆ˜ 1ìœ„(ì‹œì¥ì ìœ ìœ¨ ì•½ 30 %).
- ë³¸ì›: ì„œìš¸ ë™ëŒ€ë¬¸êµ¬ ì²œí˜¸ëŒ€ë¡œ 20, ëŒ€í‘œ 02-2250-5555, í‰ì¼ 07:30-16:00(ì ì‹¬ 12-14), í† /ê³µíœ´ì¼ ë¶„ì›ë³„ ìš´ì˜.
- ì£¼ìš” ë¶„ì›: ì†¡íŒŒ(02-2152-6555), ê°•ë‚¨, ìˆ˜ì§€, ë¶€ì‚° ì™¸ 8ê°œ êµ­ë‚´ ë¶„ì› + ì¤‘êµ­ ì‹¬ì–‘ ë¶„ì›.
- í•µì‹¬ ì„œë¹„ìŠ¤: IVFÂ·ìì—°ì£¼ê¸° IVFÂ·ICSI, Time-lapse/IMSI/PICSI/AI ë°°ì•„ì„ ë³„, ë°°ì•„Â·ì •ì ëƒ‰ë™, ì‹¬ë¦¬Â·ì˜ì–‘Â·ìŒì•…ì¹˜ë£Œ.

### ìƒë‹´ ê°€ì´ë“œ
1. **ì˜ë£Œ í•œê³„**: ì§„ë‹¨Â·ì²˜ë°©ì€ ì œê³µí•˜ì§€ ì•ŠìŒ. ì‘ê¸‰ ì¦ìƒ ì•ˆë‚´ í›„ "ì¦‰ì‹œ 119 ë˜ëŠ” ì‘ê¸‰ì‹¤" ì•ˆë‚´.
2. **ì–¸ì–´**: ì¡´ëŒ“ë§ í•œêµ­ì–´, í•„ìš” ì‹œ ì˜ì–´Â·ì¤‘êµ­ì–´Â·ë² íŠ¸ë‚¨ì–´ ì§€ì›(í†µì—­ ì„œë¹„ìŠ¤ ì œê³µ ì—¬ë¶€ ì•ˆë‚´).
3. **ì˜ˆì•½ íë¦„**  
   (1) ë‚ ì§œ â–¶ (2) ì‹œê°„ â–¶ (3) ì˜ì‚¬ â–¶ (4) ê°œì¸ì •ë³´(ì´ë¦„Â·ì—°ë½ì²˜) â–¶ (5) í™•ì¸Â·DB ì €ì¥ â–¶ (6) ì„±ê³µ ë©”ì„¸ì§€.
4. **ì¦ìƒ ì…€í”„ì²´í¬**  
   - ì¹´í…Œê³ ë¦¬: ë³µí†µÂ·ì¶œí˜ˆÂ·ë°œì—´Â·í˜¸ë¥´ëª¬ ì´ìƒ ë“±.  
   - 5ë‹¨ê³„ ë¬¸ì§„ í›„ 'ìê°€ê´€ë¦¬/ë‚´ì› ê¶Œì¥/ì‘ê¸‰' 3ë‹¨ê³„ë¡œ ë¶„ë¥˜.
5. **ê³¼ëª©ë³„ ìƒë‹´**: ë‚´ê³¼Â·ì‚°ë¶€ì¸ê³¼(ë‚œì„/ì„ì‹ ì¤€ë¹„Â·ì‚°ì „ê´€ë¦¬)Â·ì†Œì•„ì²­ì†Œë…„ê³¼Â·í”¼ë¶€ê³¼. ê° ê³¼ FAQ ìš°ì„ ê²€ìƒ‰ í›„ ë‹µë³€, ëª¨í˜¸í•  ê²½ìš° ì˜ˆì•½ ì œì•ˆ.
6. **FAQ**: ìš´ì˜ì‹œê°„, ê²€ì‚¬/ì‹œìˆ  ì¤€ë¹„, ë¹„ìš©Â·ë³´í—˜, ì£¼ì°¨ ë“± ì‚¬ì „ ë“±ë¡ëœ ë°ì´í„° ìš°ì„  í™œìš©.
7. **ìœ„ì¹˜/ì—°ë½ì²˜**: ë¶„ì›ë³„ ì§€ë²ˆÂ·ë„ë¡œëª…Â·ëŒ€ì¤‘êµí†µ ì•ˆë‚´. "ì „í™” ì—°ê²°" ë²„íŠ¼ ì¶œë ¥.
8. **ë¬¸ì§„ í›„ ê°„í˜¸ì‚¬ ì—°ê²°**: ì´ë¦„, ë‚˜ì´, ì¦ìƒ ìš”ì•½, ë³µìš©ì•½ ì…ë ¥ ë°›ê¸° â†’ ë‹´ë‹¹ì ì±„ë„ë¡œ Push.
9. **ì‘ë‹µ í˜•ì‹**  
   - ê°„ê²°í•˜ê³  ì¹œì ˆí•œ í†¤, ë‹¨ê³„ë³„ ì•ˆë‚´.  
   - ì¤‘ìš”í•œ ìˆ«ìÂ·ì‹œê°„ì€ **êµµê²Œ** í‘œì‹œ.  
   - ëë§ºìŒì— "ì¶”ê°€ ê¶ê¸ˆì¦ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš” ğŸ˜Š" í¬í•¨.

### ê¸ˆì§€ì‚¬í•­
- ì˜í•™ì  í™•ì • ì§„ë‹¨Â·ì•½ ì²˜ë°©Â·ìˆ˜ìˆ  ê¶Œìœ .  
- ê³¼ë„í•œ ê°œì¸ ì •ë³´ ìš”êµ¬.  
- ë¶€ì •í™•í•œ í†µê³„Â·ê·¼ê±° ì—†ëŠ” ì˜í•™ ì •ë³´.

(ì´ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œë˜ì§€ ì•Šì€ ì§ˆë¬¸ì€ ì˜ë£Œë²•Â·ë³‘ì› ì •ì±…ì— ì–´ê¸‹ë‚˜ì§€ ì•ŠëŠ” ë²”ìœ„ì—ì„œ ìƒì‹ì ìœ¼ë¡œ ì‘ë‹µ)`;

const SUGGESTION_SYSTEM_PROMPT = `ë‹¹ì‹ ì€ ë§ˆë¦¬ì•„ ì˜ì› AI ìƒë‹´ë´‡ì˜ ì œì•ˆ ì§ˆë¬¸ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í˜„ì¬ ëŒ€í™” ë§¥ë½ì„ ë¶„ì„í•˜ê³ , ì‚¬ìš©ìê°€ ë‹¤ìŒì— ë¬¼ì–´ë³¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ 3ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

### ì œì•ˆ ê·œì¹™:
1. **ë§¥ë½ ê¸°ë°˜**: í˜„ì¬ ëŒ€í™” íë¦„ì— ë§ëŠ” ë…¼ë¦¬ì  ë‹¤ìŒ ë‹¨ê³„ ì§ˆë¬¸
2. **ë³‘ì› ì„œë¹„ìŠ¤**: ë§ˆë¦¬ì•„ ì˜ì›ì˜ 6ê°€ì§€ ì£¼ìš” ì„œë¹„ìŠ¤ì™€ ì—°ê´€
3. **ê°„ê²°í•¨**: ê° ì§ˆë¬¸ì€ 15ì ì´ë‚´, ë²„íŠ¼ì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” ê¸¸ì´
4. **ë‹¤ì–‘ì„±**: ì„œë¡œ ë‹¤ë¥¸ ì£¼ì œë‚˜ ê´€ì ì˜ ì§ˆë¬¸ë“¤
5. **ì‹¤ìš©ì„±**: ì‹¤ì œ í™˜ìê°€ ê¶ê¸ˆí•´í• ë§Œí•œ êµ¬ì²´ì  ì§ˆë¬¸

### ì¶œë ¥ í˜•ì‹:
ì§ˆë¬¸1|ì§ˆë¬¸2|ì§ˆë¬¸3

### ì˜ˆì‹œ:
- ì´ˆê¸° ìƒë‹´ â†’ "ì§„ë£Œì‹œê°„ ë¬¸ì˜|ì˜ˆì•½ ë°©ë²•|ë¹„ìš© ì•ˆë‚´"
- ì˜ˆì•½ ê´€ë ¨ â†’ "ì˜ì‚¬ ì„ íƒ|ê²€ì‚¬ ì¤€ë¹„|ì£¼ì°¨ ì •ë³´"  
- ì¦ìƒ ë¬¸ì˜ â†’ "ì „ë¬¸ì˜ ìƒë‹´|ì‘ê¸‰ë„ í™•ì¸|ì¤€ë¹„ë¬¼ ì•ˆë‚´"`;

// íƒ€ì… ì •ì˜
interface Message {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

interface RequestBody {
  messages: Message[];
  type?: 'chat' | 'suggestions';
}

// Vercel Edge Function handler
export default async function handler(request: Request) {
  // CORS í—¤ë” ì„¤ì •
  const corsHeaders = {
    'Access-Control-Allow-Origin': '*',
    'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',
    'Access-Control-Allow-Headers': 'Content-Type, Authorization',
  };

  // OPTIONS ìš”ì²­ ì²˜ë¦¬ (CORS preflight)
  if (request.method === 'OPTIONS') {
    return new Response(null, {
      status: 200,
      headers: corsHeaders,
    });
  }

  // POST ìš”ì²­ë§Œ í—ˆìš©
  if (request.method !== 'POST') {
    return new Response(
      JSON.stringify({ error: 'Method Not Allowed' }),
      { 
        status: 405,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      }
    );
  }

  try {
    const body: RequestBody = await request.json();
    const { messages, type = 'chat' } = body;

    if (!messages || !Array.isArray(messages)) {
      return new Response(
        JSON.stringify({ error: 'Messages array is required' }),
        { 
          status: 400,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' }
        }
      );
    }

    if (type === 'suggestions') {
      // ì œì•ˆ ì§ˆë¬¸ ìƒì„±
      const conversationContext = messages
        .slice(-4)
        .map((msg: Message) => `${msg.role}: ${msg.content}`)
        .join('\n');

      const suggestionMessages: Message[] = [
        { role: 'system', content: SUGGESTION_SYSTEM_PROMPT },
        { 
          role: 'user', 
          content: `í˜„ì¬ ëŒ€í™” ë§¥ë½:\n${conversationContext}\n\nìœ„ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ë‹¤ìŒì— ë¬¼ì–´ë³¼ë§Œí•œ ìì—°ìŠ¤ëŸ¬ìš´ ì§ˆë¬¸ 3ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.` 
        }
      ];

      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: suggestionMessages,
        temperature: 0.8,
        max_tokens: 150
      });

      const suggestions = response.choices[0]?.message?.content?.trim();
      
      if (suggestions && suggestions.includes('|')) {
        const questions = suggestions.split('|').map(q => q.trim()).filter(q => q.length > 0);
        return new Response(
          JSON.stringify({ suggestions: questions.slice(0, 3) }),
          { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        );
      }
      
      return new Response(
        JSON.stringify({ suggestions: ['ì§„ë£Œì‹œê°„ ë¬¸ì˜', 'ì˜ˆì•½ ë°©ë²•', 'ë¹„ìš© ì•ˆë‚´'] }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // ì¼ë°˜ ì±„íŒ… ì‘ë‹µ
    const openaiMessages: Message[] = [
      { role: 'system', content: MARIA_HOSPITAL_SYSTEM_PROMPT },
      ...messages.map((msg: Message) => ({
        role: msg.role,
        content: msg.content
      }))
    ];

    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: openaiMessages,
      temperature: 0.7,
      max_tokens: 500
    });

    const content = response.choices[0]?.message?.content || 
      'ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.';

    return new Response(
      JSON.stringify({ content }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error) {
    console.error('OpenAI API ì˜¤ë¥˜:', error);
    return new Response(
      JSON.stringify({ error: 'ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.' }),
      { 
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' }
      }
    );
  }
} 